"""
Output generator for ArduPilot parameter files and reports
Creates parameter files that can be uploaded to ArduPilot and detailed analysis reports
"""

import os
import json
import datetime
from typing import Dict, List, Optional
import pandas as pd

class OutputGenerator:
    def __init__(self):
        self.supported_formats = ['param', 'json', 'csv', 'txt']
        
    def generate_all(self, results: Dict, output_dir: str = "output") -> Dict:
        """
        Generate all output files
        
        Args:
            results (Dict): Analysis results from PIDAutoTuner
            output_dir (str): Output directory path
            
        Returns:
            Dict: Paths to generated files
        """
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
        generated_files = {}
        
        # Generate parameter file for ArduPilot
        if results.get('optimized_parameters'):
            param_file = self.generate_parameter_file(
                results['optimized_parameters'], 
                output_dir
            )
            generated_files['parameter_file'] = param_file
        
        # Generate human-readable report
        report_file = self.generate_analysis_report(results, output_dir)
        generated_files['analysis_report'] = report_file
        
        # Generate recommendations file
        if results.get('recommendations'):
            recommendations_file = self.generate_recommendations_file(
                results['recommendations'], 
                output_dir
            )
            generated_files['recommendations_file'] = recommendations_file
        
        # Generate parameter comparison file
        if results.get('original_parameters') and results.get('optimized_parameters'):
            comparison_file = self.generate_parameter_comparison(
                results['original_parameters'],
                results['optimized_parameters'],
                output_dir
            )
            generated_files['parameter_comparison'] = comparison_file
        
        # Generate JSON export
        json_file = self.generate_json_export(results, output_dir)
        generated_files['json_export'] = json_file
        
        return generated_files
    
    def generate_parameter_file(self, optimized_params: Dict, output_dir: str) -> str:
        """
        Generate ArduPilot parameter file (.param)
        
        Args:
            optimized_params (Dict): Optimized parameters
            output_dir (str): Output directory
            
        Returns:
            str: Path to generated parameter file
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        param_file = os.path.join(output_dir, f"optimized_parameters_{timestamp}.param")
        
        with open(param_file, 'w') as f:
            # Write header
            f.write(f"# ArduPilot Parameter File\\n")
            f.write(f"# Generated by PID Auto-Tuner on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n")
            f.write(f"# \\n")
            f.write(f"# IMPORTANT: Test these parameters carefully!\\n")
            f.write(f"# Always back up your original parameters before applying changes.\\n")
            f.write(f"# \\n")
            f.write(f"\\n")
            
            # Write parameters in ArduPilot format
            for param_name, value in sorted(optimized_params.items()):
                if isinstance(value, (int, float)):
                    f.write(f"{param_name},{value:.6f}\\n")
                else:
                    f.write(f"{param_name},{value}\\n")
        
        return param_file
    
    def generate_analysis_report(self, results: Dict, output_dir: str) -> str:
        """
        Generate detailed analysis report
        
        Args:
            results (Dict): Analysis results
            output_dir (str): Output directory
            
        Returns:
            str: Path to generated report file
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(output_dir, f"analysis_report_{timestamp}.txt")
        
        with open(report_file, 'w') as f:
            f.write("ARDUPILOT PID AUTO-TUNER ANALYSIS REPORT\\n")
            f.write("=" * 50 + "\\n")
            f.write(f"Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n")
            
            # PID Analysis Section
            if 'pid' in results.get('analysis_data', {}):
                f.write("PID PERFORMANCE ANALYSIS\\n")
                f.write("-" * 30 + "\\n")
                
                pid_data = results['analysis_data']['pid']
                overall_score = pid_data.get('overall_score', 0)
                
                f.write(f"Overall Performance Score: {overall_score:.1f}/100\\n")
                f.write(f"Performance Rating: {self._get_performance_rating(overall_score)}\\n\\n")
                
                # Individual axis analysis
                for axis in ['roll', 'pitch', 'yaw']:
                    if axis in pid_data:
                        f.write(f"{axis.upper()} AXIS ANALYSIS:\\n")
                        axis_data = pid_data[axis]
                        
                        f.write(f"  Performance Score: {axis_data.get('performance_score', 0):.1f}/100\\n")
                        f.write(f"  Tracking Error (RMS): {axis_data.get('tracking_error_rms', 0):.4f} rad/s\\n")
                        f.write(f"  Maximum Tracking Error: {axis_data.get('tracking_error_max', 0):.4f} rad/s\\n")
                        
                        # Oscillation metrics
                        osc_metrics = axis_data.get('oscillation_metrics', {})
                        f.write(f"  Oscillation Frequency: {osc_metrics.get('frequency', 0):.1f} Hz\\n")
                        f.write(f"  Oscillation Amplitude: {osc_metrics.get('amplitude', 0):.4f} rad/s\\n")
                        f.write(f"  Damping Ratio: {osc_metrics.get('damping_ratio', 0):.2f}\\n")
                        
                        # Stability metrics
                        stability = axis_data.get('stability_metrics', {})
                        f.write(f"  Stability Score: {stability.get('stability_score', 0):.2f}\\n")
                        
                        # Step response analysis
                        step_responses = axis_data.get('step_responses', [])
                        if step_responses:
                            valid_responses = [sr for sr in step_responses if sr.get('valid', False)]
                            if valid_responses:
                                avg_overshoot = sum(sr.get('overshoot', 0) for sr in valid_responses) / len(valid_responses)
                                avg_settling = sum(sr.get('settling_time', 0) for sr in valid_responses) / len(valid_responses)
                                f.write(f"  Average Overshoot: {avg_overshoot:.1f}%\\n")
                                f.write(f"  Average Settling Time: {avg_settling:.3f} seconds\\n")
                        
                        f.write("\\n")
                
                # Stability assessment
                stability_analysis = pid_data.get('stability_analysis', {})
                if stability_analysis:
                    f.write("STABILITY ASSESSMENT:\\n")
                    f.write(f"  Overall Stable: {stability_analysis.get('overall_stable', True)}\\n")
                    for axis in ['roll', 'pitch', 'yaw']:
                        osc_key = f'{axis}_oscillation'
                        if osc_key in stability_analysis:
                            f.write(f"  {axis.title()} Oscillation: {stability_analysis[osc_key]}\\n")
                    f.write("\\n")
                
                # Enhanced performance analysis
                detailed_metrics = pid_data.get('detailed_metrics', {})
                if detailed_metrics:
                    f.write("DETAILED PERFORMANCE ANALYSIS\\n")
                    f.write("-" * 30 + "\\n")
                    
                    # Flight information
                    flight_info = detailed_metrics.get('flight_info', {})
                    if flight_info:
                        f.write(f"Flight Duration: {flight_info.get('duration_seconds', 0):.1f} seconds\\n")
                        f.write(f"Data Rate: {flight_info.get('data_rate_hz', 0):.1f} Hz\\n")
                        f.write(f"Data Quality: {flight_info.get('data_quality', 'unknown').upper()}\\n")
                        f.write(f"Total Samples: {flight_info.get('total_samples', 0)}\\n\\n")
                    
                    # Control authority analysis
                    control_authority = detailed_metrics.get('control_authority', {})
                    if control_authority:
                        f.write("CONTROL AUTHORITY ANALYSIS:\\n")
                        for axis in ['roll', 'pitch', 'yaw']:
                            if axis in control_authority:
                                auth_data = control_authority[axis]
                                f.write(f"  {axis.title()} Authority Utilization: {auth_data.get('authority_utilization', 0):.1f}%\\n")
                                f.write(f"  {axis.title()} Linearity Score: {auth_data.get('linearity_score', 0):.1f}%\\n")
                                f.write(f"  {axis.title()} Max Rate Achieved: {auth_data.get('max_rate_achieved', 0):.2f} rad/s\\n")
                        f.write("\\n")
                    
                    # Saturation analysis
                    saturation_analysis = detailed_metrics.get('saturation_analysis', {})
                    if saturation_analysis:
                        f.write("SATURATION ANALYSIS:\\n")
                        for axis in ['roll', 'pitch', 'yaw']:
                            if axis in saturation_analysis:
                                sat_data = saturation_analysis[axis]
                                f.write(f"  {axis.title()} Saturation: {sat_data.get('saturation_percentage', 0):.1f}% of flight\\n")
                                f.write(f"  {axis.title()} Saturation Events: {sat_data.get('saturation_events', 0)}\\n")
                                f.write(f"  {axis.title()} Severity: {sat_data.get('severity', 'unknown').upper()}\\n")
                        f.write("\\n")
                    
                    # Performance consistency
                    consistency_metrics = detailed_metrics.get('consistency_metrics', {})
                    if consistency_metrics:
                        f.write("PERFORMANCE CONSISTENCY:\\n")
                        for axis in ['roll', 'pitch', 'yaw']:
                            if axis in consistency_metrics:
                                cons_data = consistency_metrics[axis]
                                f.write(f"  {axis.title()} Consistency Score: {cons_data.get('consistency_score', 0):.1f}%\\n")
                                f.write(f"  {axis.title()} Performance Stability: {cons_data.get('performance_stability', 'unknown').upper()}\\n")
                        f.write("\\n")
                
                # Performance trends
                performance_trends = pid_data.get('performance_trends', {})
                if performance_trends:
                    f.write("PERFORMANCE TRENDS:\\n")
                    for axis in ['roll', 'pitch', 'yaw']:
                        if axis in performance_trends:
                            trend_data = performance_trends[axis]
                            trend_direction = trend_data.get('trend_direction', 'unknown')
                            performance_trend = trend_data.get('performance_trend', 0)
                            f.write(f"  {axis.title()} Trend: {trend_direction.upper()} ({performance_trend:+.1%})\\n")
                    f.write("\\n")
            
            # Filter Analysis Section
            if 'filter' in results.get('analysis_data', {}):
                f.write("FILTER PERFORMANCE ANALYSIS\\n")
                f.write("-" * 30 + "\\n")
                
                filter_data = results['analysis_data']['filter']
                
                # Noise analysis
                noise_analysis = filter_data.get('noise_analysis', {})
                if noise_analysis:
                    noise_level = noise_analysis.get('overall_noise_level', 'unknown')
                    f.write(f"Overall Noise Level: {noise_level.upper()}\\n")
                
                # Vibration analysis
                vibration_analysis = filter_data.get('vibration_analysis', {})
                overall_vib = vibration_analysis.get('overall_assessment', {})
                if overall_vib:
                    vib_detected = overall_vib.get('vibration_detected', False)
                    f.write(f"Vibrations Detected: {vib_detected}\\n")
                    if vib_detected:
                        primary_freq = overall_vib.get('primary_frequency', 0)
                        f.write(f"Primary Vibration Frequency: {primary_freq:.1f} Hz\\n")
                
                # Filter effectiveness
                filter_effectiveness = filter_data.get('filter_effectiveness', {})
                if filter_effectiveness:
                    f.write("\\nFILTER EFFECTIVENESS:\\n")
                    for filter_type, effectiveness in filter_effectiveness.items():
                        f.write(f"  {filter_type.replace('_', ' ').title()}: {effectiveness:.1f}%\\n")
                
                f.write("\\n")
            
            # Parameter Changes Section
            if results.get('optimized_parameters'):
                f.write("RECOMMENDED PARAMETER CHANGES\\n")
                f.write("-" * 30 + "\\n")
                
                original_params = results.get('original_parameters', {})
                optimized_params = results['optimized_parameters']
                
                # Group parameters
                pid_changes = {}
                filter_changes = {}
                
                for param, new_value in optimized_params.items():
                    if 'ATC_' in param:
                        pid_changes[param] = new_value
                    else:
                        filter_changes[param] = new_value
                
                if pid_changes:
                    f.write("PID Parameters:\\n")
                    for param, new_value in sorted(pid_changes.items()):
                        old_value = original_params.get(param, 'Not set')
                        if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                            change_pct = ((new_value - old_value) / old_value) * 100 if old_value != 0 else 0
                            f.write(f"  {param}: {old_value:.6f} → {new_value:.6f} ({change_pct:+.1f}%)\\n")
                        else:
                            f.write(f"  {param}: {old_value} → {new_value}\\n")
                    f.write("\\n")
                
                if filter_changes:
                    f.write("Filter Parameters:\\n")
                    for param, new_value in sorted(filter_changes.items()):
                        old_value = original_params.get(param, 'Not set')
                        if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                            change_pct = ((new_value - old_value) / old_value) * 100 if old_value != 0 else 0
                            f.write(f"  {param}: {old_value:.6f} → {new_value:.6f} ({change_pct:+.1f}%)\\n")
                        else:
                            f.write(f"  {param}: {old_value} → {new_value}\\n")
                    f.write("\\n")
            
            # Safety warnings
            f.write("SAFETY WARNINGS AND RECOMMENDATIONS\\n")
            f.write("-" * 30 + "\\n")
            f.write("⚠️  IMPORTANT SAFETY INFORMATION:\\n")
            f.write("   • Always backup your original parameters before applying changes\\n")
            f.write("   • Test parameter changes gradually and carefully\\n")
            f.write("   • Start with small changes and increase slowly\\n")
            f.write("   • Always have a safety pilot ready during testing\\n")
            f.write("   • Monitor motor temperatures during tuning\\n")
            f.write("   • Be prepared to revert to original parameters if needed\\n")
            f.write("\\n")
            f.write("📋 TESTING PROCEDURE:\\n")
            f.write("   1. Load parameters in Mission Planner or similar GCS\\n")
            f.write("   2. Start with altitude hold or loiter mode\\n")
            f.write("   3. Test small stick inputs first\\n")
            f.write("   4. Gradually increase input magnitude\\n")
            f.write("   5. Monitor for oscillations or instability\\n")
            f.write("   6. Record new logs for verification\\n")
        
        return report_file
    
    def generate_recommendations_file(self, recommendations: List[Dict], output_dir: str) -> str:
        """
        Generate recommendations file
        
        Args:
            recommendations (List[Dict]): List of recommendations
            output_dir (str): Output directory
            
        Returns:
            str: Path to generated recommendations file
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        rec_file = os.path.join(output_dir, f"recommendations_{timestamp}.txt")
        
        with open(rec_file, 'w') as f:
            f.write("FLIGHT PERFORMANCE RECOMMENDATIONS\\n")
            f.write("=" * 50 + "\\n")
            f.write(f"Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n")
            
            if not recommendations:
                f.write("✅ No specific recommendations - Your flight performance looks good!\\n")
                return rec_file
            
            # Group by priority
            priority_groups = {}
            for rec in recommendations:
                priority = rec['priority']
                if priority not in priority_groups:
                    priority_groups[priority] = []
                priority_groups[priority].append(rec)
            
            priority_order = ['critical', 'high', 'medium', 'low', 'info']
            priority_icons = {
                'critical': '🚨',
                'high': '⚠️',
                'medium': '🔶',
                'low': '💡',
                'info': 'ℹ️'
            }
            
            for priority in priority_order:
                if priority in priority_groups:
                    f.write(f"{priority_icons[priority]} {priority.upper()} PRIORITY\\n")
                    f.write("-" * 30 + "\\n")
                    
                    for i, rec in enumerate(priority_groups[priority], 1):
                        f.write(f"\\n{i}. {rec['title']}\\n")
                        f.write(f"   📝 DESCRIPTION: {rec['description']}\\n")
                        f.write(f"   🔧 ACTION: {rec['action']}\\n")
                        f.write(f"   📊 IMPACT: {rec['estimated_impact']}\\n")
                        if rec.get('technical_details'):
                            f.write(f"   🔬 TECHNICAL: {rec['technical_details']}\\n")
                    
                    f.write("\\n")
            
            # Add summary
            critical_count = len(priority_groups.get('critical', []))
            high_count = len(priority_groups.get('high', []))
            
            f.write("📈 SUMMARY\\n")
            f.write("-" * 20 + "\\n")
            f.write(f"Total recommendations: {len(recommendations)}\\n")
            if critical_count > 0:
                f.write(f"🚨 Critical issues: {critical_count} - Address immediately!\\n")
            if high_count > 0:
                f.write(f"⚠️ High priority: {high_count} - Address soon\\n")
        
        return rec_file
    
    def generate_parameter_comparison(self, original_params: Dict, optimized_params: Dict, 
                                    output_dir: str) -> str:
        """
        Generate parameter comparison file
        
        Args:
            original_params (Dict): Original parameters
            optimized_params (Dict): Optimized parameters
            output_dir (str): Output directory
            
        Returns:
            str: Path to generated comparison file
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        comp_file = os.path.join(output_dir, f"parameter_comparison_{timestamp}.csv")
        
        # Create comparison data
        comparison_data = []
        
        for param in sorted(set(list(original_params.keys()) + list(optimized_params.keys()))):
            original_value = original_params.get(param, 'Not set')
            optimized_value = optimized_params.get(param, 'No change')
            
            # Calculate change percentage
            change_pct = ''
            if (isinstance(original_value, (int, float)) and 
                isinstance(optimized_value, (int, float)) and 
                original_value != 0):
                change_pct = f"{((optimized_value - original_value) / original_value) * 100:+.1f}%"
            
            comparison_data.append({
                'Parameter': param,
                'Original_Value': original_value,
                'Optimized_Value': optimized_value,
                'Change_Percentage': change_pct,
                'Category': self._categorize_parameter(param)
            })
        
        # Write to CSV
        df = pd.DataFrame(comparison_data)
        df.to_csv(comp_file, index=False)
        
        return comp_file
    
    def generate_json_export(self, results: Dict, output_dir: str) -> str:
        """
        Generate JSON export of all results
        
        Args:
            results (Dict): Analysis results
            output_dir (str): Output directory
            
        Returns:
            str: Path to generated JSON file
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        json_file = os.path.join(output_dir, f"analysis_results_{timestamp}.json")
        
        # Prepare data for JSON serialization
        json_data = {
            'metadata': {
                'generated_at': datetime.datetime.now().isoformat(),
                'generator': 'PID Auto-Tuner v1.0.0',
                'format_version': '1.0'
            },
            'results': self._prepare_for_json(results)
        }
        
        with open(json_file, 'w') as f:
            json.dump(json_data, f, indent=2, default=str)
        
        return json_file
    
    def _prepare_for_json(self, data):
        """Prepare data for JSON serialization"""
        if isinstance(data, dict):
            return {key: self._prepare_for_json(value) for key, value in data.items()}
        elif isinstance(data, list):
            return [self._prepare_for_json(item) for item in data]
        elif isinstance(data, (int, float, str, bool, type(None))):
            return data
        else:
            return str(data)
    
    def _get_performance_rating(self, score: float) -> str:
        """Get performance rating from score"""
        if score >= 90:
            return "EXCELLENT"
        elif score >= 80:
            return "GOOD"
        elif score >= 70:
            return "FAIR"
        elif score >= 50:
            return "POOR"
        else:
            return "VERY POOR"
    
    def _categorize_parameter(self, param_name: str) -> str:
        """Categorize parameter by name"""
        if 'ATC_RAT_' in param_name:
            return 'Rate Controller PID'
        elif 'ATC_ANG_' in param_name:
            return 'Angle Controller PID'
        elif 'INS_GYRO_' in param_name:
            return 'Gyro Filter'
        elif 'INS_ACCEL_' in param_name:
            return 'Accelerometer Filter'
        elif 'INS_NOTCH_' in param_name:
            return 'Notch Filter'
        elif 'FILT' in param_name:
            return 'Rate Controller Filter'
        else:
            return 'Other'